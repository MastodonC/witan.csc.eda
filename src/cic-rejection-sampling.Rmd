---
title: "CiC Rejection Sampling"
output: html_notebook
---

This workbook is responsible for creating a target duration distribution for each join age.

We use this distribution for calculating rejection sampling proportions and also for comparing our outputs against.

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
library(lubridate)
library(survival)
library(survminer)
library(stringr)
library(reshape2)
library(zoo)
library(dplyr)
library(tidyr)
```

```{r}
source("helpers.R")
```



```{r}
input_csv <- "/Users/henry/Mastodon C/witan.cic/data/scc/2020-12-04/suffolk-scrubbed-episodes-20201203.csv"
output_csv <- "/Users/henry/Mastodon C/witan.cic/data/scc/2020-12-04/target-distribution.csv"
open_durations_csv <- "/Users/henry/Mastodon C/witan.cic/data/scc/2020-12-04/open-durations.csv"

data <- read.csv(input_csv)
data$report_date <- ymd(data$report_date)
data$ceased <- ymd(data$ceased)

data.frame(xs = c(data$report_date, data$ceased)) %>%
  filter(!is.na(xs)) %>%
  filter(xs > as.Date("2020-01-01")) %>%
  ggplot(aes(xs)) + geom_histogram()

# We want to fix the input and remove any data after 31st March


# Fix dodgy NAs
extract_date <- as.Date("2020-03-31")
data$ceased[data$ceased > extract_date] <- NA
data <- data[data$report_date <= extract_date,]

data %>% filter(duration == 1)
```

```{r}

# Creates data that will be fed to the survival curve fitting model.
# We only know which month each child's birthday falls in, so we create a record
# for each day of this month.

binomial_noise <- Vectorize(function(val, max_val) {
  p <- max(1.0 / max_val, min(1.0, val / max_val))
  max(rbinom(n = 1, size = max_val, prob = p), 1)
})

impute_birthday <- Vectorize(function(lower, upper) {
  lower + days(as.integer(round(runif(1, 0, as.numeric(difftime(upper, lower, units = "days"))))))
})

eighteen_years_before <- function(date) {
  if_else(day(date)==29 & month(date) == 2,
    date + days(1) - years(18),
    date - years(18))
}

eighteen_years_after <- function(date) {
  if_else(day(date)==29 & month(date) == 2,
    date + days(1) + years(18),
    date + years(18))
  }

survival_data <- data %>%
  mutate(report_date = ymd(report_date),
         ceased = ymd(ceased),
         max_date = max(c(report_date, ceased), na.rm = TRUE)) %>%
  group_by(period_id) %>%
  dplyr::summarise(period_start = min(report_date),
                   period_end = max(ceased),
                   birth_month_beginning = ymd(paste0(DOB[1], "-01")),
                   birth_month_end = birth_month_beginning + months(1) - days(1),
                   max_date = max_date[1])

survival_data2 <- survival_data %>%
  mutate(birthday_lower = pmax(birth_month_beginning, eighteen_years_before(replace_na(period_end, max_date[1]))),
         birthday_upper = pmin(birth_month_end, period_start),
         aged_out = birthday_lower > birthday_upper,
         period_end = if_else(aged_out, eighteen_years_after(birthday_upper) - days(1), period_end),
         event = !is.na(period_end),
         duration = if_else(event,
                            day_diff(period_start, period_end),
                            day_diff(period_start, max(period_start, period_end, na.rm = TRUE))))

survival_data2 %>% filter(birthday_lower > birthday_upper)

survival_data3 <- survival_data2 %>%
  mutate(aged_out = birthday_lower > birthday_upper,
         birthday_lower = if_else(aged_out, birthday_upper, birthday_lower),
         duration = if_else(aged_out, day_diff(birthday_upper, eighteen_years_after(birthday_upper) - 1), duration)
         ) %>%
  inner_join(data.frame(n = 1:100), by = character()) %>%
  mutate(birthday = as.Date(impute_birthday(birthday_lower, birthday_upper), origin = "1970-01-01"),
         admission_age = as.factor(clamp(year_diff(birthday, period_start), 0, 17)),
         max_duration = day_diff(period_start, eighteen_years_after(birthday) - days(1)),
         fuzzed_duration = binomial_noise(duration, max_duration)
         ) %>%
  as.data.frame

max_date <- max(c(data$report_date, data$ceased), na.rm = TRUE)
rewind_date <- max_date - years(1)

open_period_durations <- survival_data3 %>%
  filter(period_start <= rewind_date & (is.na(period_end) | period_end > rewind_date)) %>%
  dplyr::select(period_id, admission_age, duration) %>%
  mutate(duration_group = floor(duration / 7))

survival_data3 %>% filter(period_id %in% c('1380-1',
'3373-1',
'3880-1'))

write.csv(open_period_durations, file = open_durations_csv, row.names = FALSE)

data %>% filter(period_id %in% (survival_data2 %>% filter(duration == 1))$period_id)

```


```{r}
survival_data3 %>% filter(period_id == "3747-1")

survival_data3 %>% group_by(period_id) %>% slice(1) %>% arrange(duration) %>% filter(event)
```


```{r}
fit <- survfit(Surv(fuzzed_duration, event) ~ admission_age, data = survival_data3)
quantiles <- reshape2::melt(stats::quantile(fit, probs = seq(0,0.9999,length.out = 10000))$quantile) %>%
  mutate(join_age = as.integer(str_replace(Var1, "admission_age=", ""))) %>%
  select(-1) %>%
  as.data.frame
colnames(quantiles) <- c("quantile", "duration", "admission_age")

quantiles <- dcast(admission_age ~ quantile, data = quantiles, drop = FALSE, value.var = "duration")
for (row in 1:18) {
  # I expect there's a better way of doing this
  age <- row - 1
  max_days <- (18 - age) * 365
  quantiles[row,is.na(quantiles[row,])] <- max_days
  quantiles[row,quantiles[row,] > max_days] <- max_days

}
quantiles <- cbind(quantiles, data.frame(`100` = 18:1*365))
colnames(quantiles) <- c("admission_age", seq(0, 10000, length.out = ncol(quantiles) - 1))
quantiles <- melt(quantiles, id.vars = "admission_age") %>%
  mutate(quantile = as.numeric(variable) / 10000.0,
         duration = value) %>%
  select(admission_age, duration, quantile) %>%
  group_by(admission_age, duration) %>%
  summarise(quantile = max(quantile))

target_distribution <- quantiles %>%
  mutate(duration_group = duration %/% 7) %>%
  group_by(admission_age, duration_group) %>%
  summarise(quantile = max(quantile)) %>%
  arrange(admission_age, duration_group) %>%
  mutate(density = quantile - coalesce(lag(quantile), 0)) %>%
  mutate(density = density * 100 / sum(density))

write.csv(target_distribution, file = output_csv, row.names = FALSE)
```

Let's plot the target distribution to see what we have...

```{r}
ggplot(target_distribution, aes(duration_group, density)) +
  geom_bar(stat = "identity") +
  facet_wrap(vars(admission_age), scales = "free_y")

for (age in 0:17) {
  print(ggplot(target_distribution %>% filter(admission_age == age), aes(duration_group, density)) +
    geom_bar(stat = "identity") +
    facet_wrap(vars(admission_age), scales = "free_y"))
}
```


```{r}
library(DBI)
library(RPostgreSQL)
drv <- dbDriver("PostgreSQL")
conn <- dbConnect(drv, dbname = "henry")
```

```{sql connection=conn}
DROP TABLE IF EXISTS mastodon.target_distribution;

CREATE TABLE mastodon.target_distribution (
    admission_age integer,
    duration_group integer,
    density double precision
);
```

At this point you should load the target distribution and the open period durations tables from the CSVs you've just created

We create versions of the input periods to try and get good coverage of the whole target distribution.
This means adjusting the total duration by up to 10 weeks either way.
We don't filter periods which go over 18 because we adjust the birthdays in the following section.

```{sql connection=conn}
DROP TABLE mastodon.fuzzy_periods;

CREATE TABLE mastodon.fuzzy_periods AS
WITH noise AS (
  SELECT generate_series(-10, 10) * 7 AS noise
)
SELECT p.provenance, p.id, p.sample_index, p.admission_age, p.admission_age_days,
  cast(p.duration + noise AS int) AS duration, CAST(duration + noise AS int) / 7 AS duration_group, episodes_edn
FROM mastodon.periods AS p
  CROSS JOIN noise
WHERE duration + noise >= 28;
```

For all those who join aged at least 1, we create versions of all simulated and projected data with fuzzed birthdays: up to 5 weeks in either direction.


```{sql connection=conn}
WITH noise AS (
  SELECT generate_series(-5, 5) * 7 AS noise
)
INSERT INTO mastodon.fuzzy_periods
SELECT p.provenance, p.id, p.sample_index, CAST(p.admission_age_days + noise AS int) / 365, CAST(p.admission_age_days + noise AS int) AS admission_age_days, p.duration, p.duration_group, episodes_edn
FROM mastodon.fuzzy_periods AS p
CROSS JOIN noise
WHERE noise != 0 AND CAST(p.admission_age_days + noise AS int) / 365 >= 1
AND provenance IN ('S', 'P');
```

Having done this we now have a target distribution and some fuzzy periods that we'll be drawing from to match it.

In order to determine what probability to assign to each of the sources we need to calculate the relative density of the candidate distribution relative to the targets. Projected data has a different target distribution from simulated data.

```{r}
candidate_duration_groups <- dbGetQuery(conn, "SELECT admission_age, duration_group, COUNT(*) AS density
                                  FROM mastodon.fuzzy_periods
                                  WHERE provenance = 'S'
                                  GROUP BY admission_age, duration_group")

for (age in 0:17) {
  print(ggplot(candidate_duration_groups %>% filter(admission_age == age), aes(duration_group, density)) +
    geom_bar(stat = "identity") +
    facet_wrap(vars(admission_age), scales = "free_y"))
}
```


```{sql connection=conn}
DROP TABLE mastodon.candidate_distributions;

CREATE TABLE mastodon.candidate_distributions AS
SELECT provenance, admission_age, duration_group, COUNT(*) AS density
FROM mastodon.fuzzy_periods
GROUP BY provenance, admission_age, duration_group;

DROP TABLE mastodon.target_projected_distribution;

CREATE TABLE mastodon.target_projected_distribution AS
WITH open_period_durations AS (
  SELECT *, CAST(duration AS int) / 7 AS duration_group
  FROM mastodon.periods
  WHERE provenance = 'C'
),
target_projected_distribution AS (
  SELECT pp.admission_age, td.duration_group, CASE WHEN pp.duration_group = td.duration_group THEN density * (7 - (pp.duration % 7)) ELSE density END AS density
  FROM open_period_durations pp
  INNER JOIN mastodon.target_distribution td
  ON pp.admission_age = td.admission_age
  AND td.duration_group >= pp.duration_group
)
SELECT admission_age, duration_group, SUM(density) AS density
FROM target_projected_distribution
GROUP BY admission_age, duration_group;

```

```{r}
candidate_duration_groups <- dbGetQuery(conn, "SELECT admission_age, duration_group, density
                                  FROM mastodon.candidate_distributions
                                  WHERE provenance = 'S'")

for (age in 0:17) {
  print(ggplot(candidate_duration_groups %>% filter(admission_age == age), aes(duration_group, density)) +
    geom_bar(stat = "identity") +
    facet_wrap(vars(admission_age), scales = "free_y"))
}

target_duration_groups <- dbGetQuery(conn, "SELECT admission_age, duration_group, density
                                  FROM mastodon.target_distribution")

for (age in 0:17) {
  print(ggplot(target_duration_groups %>% filter(admission_age == age), aes(duration_group, density)) +
    geom_bar(stat = "identity") +
    facet_wrap(vars(admission_age), scales = "free_y"))
}


target_projected_duration_groups <- dbGetQuery(conn, "SELECT admission_age, duration_group, density
                                  FROM mastodon.target_projected_distribution")

for (age in 0:17) {
  print(ggplot(target_projected_duration_groups %>% filter(admission_age == age), aes(duration_group, density)) +
    geom_bar(stat = "identity") +
    facet_wrap(vars(admission_age), scales = "free_y"))
}
```

We need to ensure that every ID to be projected has at least one period with a non-zero density in the target (otherwise it will never be chosen)

```{r}

non_join_duration_groups <- dbGetQuery(conn, "WITH empty_ids AS (
SELECT fp.id
FROM mastodon.fuzzy_periods fp
LEFT OUTER JOIN mastodon.target_projected_distribution pd
ON fp.admission_age = pd.admission_age
AND fp.duration_group = pd.duration_group
WHERE fp.provenance = 'P'
GROUP BY fp.id
HAVING SUM(coalesce(pd.density, 0)) = 0
)SELECT id, admission_age, duration_group, COUNT(*) AS density
FROM mastodon.fuzzy_periods
WHERE id IN (SELECT id FROM empty_ids)
AND provenance = 'P'
GROUP BY id, admission_age, duration_group;")

combined_duration_groups <- rbind(cbind(id = "target", target_projected_duration_groups),
      non_join_duration_groups) %>%
  group_by(id, admission_age) %>%
  mutate(density = density / max(density)) 

for (age in 0:17) {
  print(ggplot(combined_duration_groups %>% filter(admission_age == age), aes(duration_group, density, fill = id)) +
  geom_bar(stat = "identity", position = "fill") +
  facet_wrap(vars(admission_age)))
}


```

```{sql connection=conn}


DROP TABLE mastodon.projected_candidates;
CREATE TABLE mastodon.projected_candidates AS
WITH period_distributions AS (
  SELECT id, admission_age, duration_group, COUNT(*) AS density
  FROM mastodon.fuzzy_periods
  GROUP BY id, admission_age, duration_group
),
max_ratio AS (
  SELECT id, MAX(tpd.density / pd.density) AS max_ratio
  FROM period_distributions pd
  JOIN mastodon.target_projected_distribution tpd
  ON pd.admission_age = tpd.admission_age
  AND pd.duration_group = tpd.duration_group
  GROUP BY id
),
samples AS (
  SELECT fp.*, pd.density AS candidate_density, tpd.density AS target_density, mr.max_ratio AS max_ratio
  FROM mastodon.fuzzy_periods fp
  INNER JOIN period_distributions pd
  ON fp.id = pd.id
  AND fp.admission_age = pd.admission_age
  AND fp.duration_group = pd.duration_group
  INNER JOIN mastodon.target_projected_distribution tpd
  ON fp.admission_age = tpd.admission_age
  AND fp.duration_group = tpd.duration_group
  INNER JOIN max_ratio mr
  ON fp.id = mr.id
  WHERE fp.provenance = 'P'
),
filtered_samples AS (
  SELECT *
  FROM samples
  WHERE random() * 0.05 <= target_density / (candidate_density * max_ratio)
),
new_candidate_density AS (
  SELECT id, admission_age, duration_group, COUNT(*) AS density
  FROM filtered_samples
  GROUP BY id, admission_age, duration_group
)
SELECT s.provenance, s.id, s.sample_index, s.admission_age, s.admission_age_days, s.duration, s.duration_group, s.episodes_edn, tpd.density / d.density AS reject_ratio
FROM filtered_samples s
INNER JOIN new_candidate_density d
ON s.id = d.id
AND s.admission_age = d.admission_age
AND s.duration_group = d.duration_group
INNER JOIN mastodon.target_projected_distribution tpd
ON s.admission_age = tpd.admission_age
AND s.duration_group = tpd.duration_group;




INSERT INTO mastodon.projected_candidates
WITH missing_periods AS (
SELECT *, row_number() OVER (PARTITION BY id ORDER BY random()) AS rand_id
FROM mastodon.fuzzy_periods fp
WHERE fp.provenance = 'P'
AND id NOT IN (
  SELECT DISTINCT id
  FROM mastodon.projected_candidates
)
)
SELECT provenance, id, sample_index, admission_age, admission_age_days, duration, duration_group, episodes_edn, 1.0 AS reject_ratio
FROM missing_periods
WHERE rand_id <= 100;



DROP TABLE mastodon.simulated_candidates;
CREATE TABLE mastodon.simulated_candidates AS
WITH candidate_distribution AS (
  SELECT admission_age, duration_group, COUNT(*) AS density
  FROM mastodon.fuzzy_periods
  WHERE provenance = 'S'
  GROUP BY admission_age, duration_group
),
reject_proportions AS (
  SELECT t.admission_age, t.duration_group, t.density / c.density AS reject_ratio
  FROM mastodon.target_distribution t
  LEFT JOIN candidate_distribution c
  ON c.admission_age = t.admission_age
  AND c.duration_group = t.duration_group
),
reject_constants AS (
  SELECT admission_age, MAX(reject_ratio) AS c
  FROM reject_proportions
  GROUP BY admission_age
),
fuzzy_periods_filtered AS (
  SELECT fp.*
  FROM mastodon.fuzzy_periods fp
  INNER JOIN reject_proportions rp
  ON fp.admission_age = rp.admission_age
  AND fp.duration_group = rp.duration_group
  INNER JOIN reject_constants rc
  ON fp.admission_age = rc.admission_age
  WHERE fp.provenance = 'S'
  AND random() * 0.1 <= rp.reject_ratio / rc.c
),
candidate_distribution_filtered AS (
  SELECT admission_age, duration_group, COUNT(*) AS density
  FROM fuzzy_periods_filtered
  WHERE provenance = 'S'
  GROUP BY admission_age, duration_group
),
reject_proportions_filtered AS (
  SELECT c.admission_age, c.duration_group, t.density / c.density AS reject_ratio
  FROM mastodon.target_distribution t
  LEFT JOIN candidate_distribution_filtered c
  ON c.admission_age = t.admission_age
  AND c.duration_group = t.duration_group
)
SELECT fp.*, rp.reject_ratio
FROM fuzzy_periods_filtered fp
INNER JOIN reject_proportions_filtered rp
ON fp.admission_age = rp.admission_age
AND fp.duration_group = rp.duration_group;

```

```{sql connection=conn}
-- Projected periods
WITH candidate_projected_distribution AS (
  SELECT *
  FROM mastodon.candidate_distributions
  WHERE provenance = 'P'
),
reject_proportions AS (
  SELECT c.admission_age, c.duration_group, t.density / c.density AS reject_ratio
  FROM mastodon.target_projected_distribution t
  INNER JOIN candidate_projected_distribution c
  ON c.admission_age = t.admission_age
  AND c.duration_group = t.duration_group
)
SELECT fp.*, rp.reject_ratio
FROM mastodon.fuzzy_periods fp
INNER JOIN reject_proportions rp
ON fp.admission_age = rp.admission_age
AND fp.duration_group = rp.duration_group
WHERE fp.provenance = 'P';


WITH period_ids AS (
  SELECT id, AVG(admission_age) AS admission_age,
  AVG(duration) AS duration,
  AVG(duration_group) AS duration_group
  FROM mastodon.open_period_durations
  GROUP BY id
),
projected_periods AS (
  SELECT *
  FROM mastodon.fuzzy_periods
  WHERE provenance = 'P'
),
matched_periods AS (
  SELECT id, SUM(density)
  FROM projected_periods pp
  INNER JOIN mastodon.target_projected_distribution tp
  ON pp.admission_age = tp.admission_age
  AND pp.duration_group = tp.duration_group
  GROUP BY id
  HAVING SUM(density) > 0
)
SELECT *
FROM period_ids pi
LEFT OUTER JOIN matched_periods mp
ON pi.id = mp.id;


WITH open_periods AS (
SELECT DISTINCT id FROM mastodon.open_period_durations
),
projected_periods AS (
SELECT DISTINCT id FROM mastodon.fuzzy_periods WHERE provenance = 'P'
)
SELECT *
FROM open_periods o
FULL OUTER JOIN projected_periods p
ON o.id = p.id;

-- Check that we have good coverage

/*WITH candidate_simulated_distribution AS (
  SELECT *
  FROM mastodon.candidate_distributions
  WHERE provenance = 'S'
)
SELECT *
FROM mastodon.target_distribution t
LEFT JOIN candidate_simulated_distribution c
ON c.admission_age = t.admission_age
AND c.duration_group = t.duration_group
ORDER BY t.admission_age, t.duration_group;*/

/*WITH candidate_distribution AS (
  SELECT admission_age, duration_group, COUNT(*) AS density
  FROM mastodon.fuzzy_periods
  WHERE provenance = 'S'
  GROUP BY admission_age, duration_group
),
reject_proportions AS (
  SELECT t.admission_age, t.duration_group, t.density AS target_density, c.density AS candidate_density
  FROM mastodon.target_distribution t
  LEFT JOIN candidate_distribution c
  ON c.admission_age = t.admission_age
  AND c.duration_group = t.duration_group
),
highest_groups AS (
  SELECT admission_age, max(duration_group)
  FROM reject_proportions
  WHERE candidate_density IS NOT NULL
  GROUP BY admission_age
)
SELECT * FROM highest_groups;*/

-- Limit count probabilistically

WITH candidate_distribution AS (
  SELECT admission_age, duration_group, COUNT(*) AS density
  FROM mastodon.fuzzy_periods
  WHERE provenance = 'S'
  GROUP BY admission_age, duration_group
),
reject_proportions AS (
  SELECT t.admission_age, t.duration_group, t.density / c.density AS reject_ratio
  FROM mastodon.target_distribution t
  LEFT JOIN candidate_distribution c
  ON c.admission_age = t.admission_age
  AND c.duration_group = t.duration_group
),
reject_constants AS (
  SELECT admission_age, MAX(reject_ratio) AS c
  FROM reject_proportions
  GROUP BY admission_age
),
fuzzy_periods_filtered AS (
  SELECT fp.*
  FROM mastodon.fuzzy_periods fp
  INNER JOIN reject_proportions rp
  ON fp.admission_age = rp.admission_age
  AND fp.duration_group = rp.duration_group
  INNER JOIN reject_constants rc
  ON fp.admission_age = rc.admission_age
  WHERE fp.provenance = 'S'
  AND random() * 0.05 <= rp.reject_ratio / rc.c
),
candidate_distribution_filtered AS (
  SELECT admission_age, duration_group, COUNT(*) AS density
  FROM fuzzy_periods_filtered
  WHERE provenance = 'S'
  GROUP BY admission_age, duration_group
),
reject_proportions_filtered AS (
  SELECT c.admission_age, c.duration_group, t.density / c.density AS reject_ratio
  FROM mastodon.target_distribution t
  LEFT JOIN candidate_distribution_filtered c
  ON c.admission_age = t.admission_age
  AND c.duration_group = t.duration_group
)
SELECT fp.*, rp.reject_ratio
FROM fuzzy_periods_filtered fp
INNER JOIN reject_proportions_filtered rp
ON fp.admission_age = rp.admission_age
AND fp.duration_group = rp.duration_group;



SELECT * FROM mastodon.fuzzy_periods
WHERE id = '2000-1'
AND provenance = 'P'


WITH candidate_projected_distribution AS (
  SELECT *
  FROM mastodon.candidate_distributions
  WHERE provenance = 'P'
)
  SELECT c.admission_age, c.duration_group, t.density / c.density AS reject_ratio
  FROM mastodon.target_projected_distribution t
  LEFT JOIN candidate_projected_distribution c
  ON c.admission_age = t.admission_age
  AND c.duration_group = t.duration_group
  WHERE c.admission_age = 0
  
  
  
  
```


This is our target distribution. How did we do at matching it?

```{r}
episodes_csv <- "/Users/henry/Mastodon C/witan.cic/data/scc/2020-12-04/scc-episodes-2019-08-13-rewind-1yr-train-3yr-project-5yr-runs-100-seed-42-universe.csv"

episodes_csv <- "/Users/henry/Mastodon C/witan.cic/data/scc/2020-12-04/scc-episodes-2020-03-31-rewind-0yr-train-3yr-project-5yr-runs-100-seed-42-5-trended.csv"
```

```{r}
episodes <- read.csv(episodes_csv)

simulated_cdf <- episodes %>%
  filter(Provenance == "S") %>%
  group_by(ID) %>%
  slice(1) %>%
  rename(admission_age = Admission.Age, duration = Period.Duration, simulation = Simulation) %>%
  group_by(simulation, admission_age) %>%
  mutate(duration_group = duration %/% 7) %>%
  mutate(quantile = ecdf(duration_group)(duration_group)) %>%
  dplyr::select(simulation, admission_age, duration_group, quantile)

ggplot(simulated_cdf, aes(duration_group, quantile)) +
  geom_line(aes(group = simulation), alpha = 0.1) +
  geom_line(data = target_distribution, color = "red", linetype = 2) +
  facet_wrap(vars(admission_age))

for (age in 0:17) {
  print(ggplot(simulated_cdf %>% filter(admission_age == age), aes(duration_group, quantile)) +
    geom_line(aes(group = simulation), alpha = 0.5) +
    geom_line(data = target_distribution %>% filter(admission_age == age), color = "red", linetype = 2))
}

```

